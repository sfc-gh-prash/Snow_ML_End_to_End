{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Standard Python Libraries\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Split data into 70% training and 30% testing\n",
    "train, test = ds_sp_ohe.random_split(weights=[0.70, 0.30], seed=0)\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['MOST_COMMON_DEVICE_TYPE', 'MOST_COMMON_LOCATION',\n",
    "                       'MOST_COMMON_MERCHANT_CATEGORY', 'MOST_COMMON_TRANSACTION_DAY']\n",
    "numerical_features = ['AVG_TRANSACTION_AMOUNT', 'TRANSACTION_COUNT', 'AVG_SENTIMENT_SCORE']\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('num_imputer', SimpleImputer(\n",
    "        input_cols=numerical_features,\n",
    "        output_cols=numerical_features,\n",
    "        strategy='median'\n",
    "    )),\n",
    "    ('cat_encoder', OneHotEncoder(\n",
    "        input_cols=categorical_features,\n",
    "        output_cols=[f\"{col}_encoded\" for col in categorical_features],\n",
    "        handle_unknown='ignore'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Generate feature list\n",
    "all_features = numerical_features + [f\"{col}_encoded\" for col in categorical_features]\n",
    "\n",
    "# Define models with updated data splits\n",
    "models = {\n",
    "    \"XGBoost\": Pipeline([\n",
    "        ('preprocessor', preprocessing_pipeline),\n",
    "        ('classifier', XGBClassifier(\n",
    "            input_cols=all_features,\n",
    "            label_cols=['IS_FRAUD'],\n",
    "            output_cols=['PREDICTION'],\n",
    "            eval_metric='logloss'\n",
    "        ))\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline([\n",
    "        ('preprocessor', preprocessing_pipeline),\n",
    "        ('classifier', RandomForestClassifier(\n",
    "            input_cols=all_features,\n",
    "            label_cols=['IS_FRAUD'],\n",
    "            output_cols=['PREDICTION']\n",
    "        ))\n",
    "    ]),\n",
    "    \"LogisticRegression\": Pipeline([\n",
    "        ('preprocessor', preprocessing_pipeline),\n",
    "        ('classifier', LogisticRegression(\n",
    "            input_cols=all_features,\n",
    "            label_cols=['IS_FRAUD'],\n",
    "            output_cols=['PREDICTION']\n",
    "        ))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Model training and evaluation with new splits\n",
    "best_model = None\n",
    "best_score = 0\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} model...\")\n",
    "    model.fit(train)\n",
    "    preds = model.predict(test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    f1 = f1_score(test['IS_FRAUD'], preds['PREDICTION'])\n",
    "    precision = precision_score(test['IS_FRAUD'], preds['PREDICTION'])\n",
    "    recall = recall_score(test['IS_FRAUD'], preds['PREDICTION'])\n",
    "    \n",
    "    print(f\"{name} Metrics:\")\n",
    "    print(f\"F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\\n\")\n",
    "\n",
    "    if f1 > best_score:  # Using F1 as selection metric for fraud detection\n",
    "        best_model = model\n",
    "        best_score = f1\n",
    "\n",
    "# Register best model\n",
    "model_name = \"Fraud_Detection_Model\"\n",
    "try:\n",
    "    model_version = model_registry.get_model(model_name).version(\"v1\")\n",
    "    print(\"Updating existing model version...\")\n",
    "    model_version.set_metric(\"F1_score\", best_score)\n",
    "except:\n",
    "    print(\"Logging new model...\")\n",
    "    model_version = model_registry.log_model(\n",
    "        model_name=model_name,\n",
    "        model=best_model,\n",
    "        version_name=\"v1\",\n",
    "        sample_input_data=train,\n",
    "        comment=\"Best performing fraud detection model with 70-30 split\"\n",
    "    )\n",
    "    model_version.set_metric(\"F1_score\", best_score)\n",
    "    model_version.set_metric(\"Precision\", precision)\n",
    "    model_version.set_metric(\"Recall\", recall)\n",
    "\n",
    "print(f\"Best model: {type(best_model.steps[-1][1]).__name__} with F1-score {best_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
